{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed08f86b",
   "metadata": {},
   "source": [
    "# Segmentation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea7a4a",
   "metadata": {},
   "source": [
    "### <font color='red'> After clicking on a code cell, press \"Shift+Enter\" to run the code, or click on the \"Run\" button in the toolbar above.<br>\n",
    "\n",
    "### Replace \"...\" signs with the appropriate path to your data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96194952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tapenade import get_path_to_demo_folder\n",
    "from tapenade.preprocessing import (\n",
    "    global_contrast_enhancement,\n",
    "    local_contrast_enhancement,\n",
    "    segment_stardist\n",
    ")\n",
    "from tapenade import get_path_to_demo_folder\n",
    "from tapenade.preprocessing import change_array_pixelsize\n",
    "from tapenade.preprocessing.segmentation_postprocessing import remove_small_objects, remove_labels_outside_of_mask\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from pathlib import Path\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f469a65",
   "metadata": {},
   "source": [
    "Enter the path to the image you want to segment. The mask is optional, but it is recommended if you use the local contrast enhancement method (and do not load data that is already enhanced that way) or if you need to post-process the segmentation results (e.g to remove labels outside the mask or touching the borders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e5d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = get_path_to_demo_folder()\n",
    "\n",
    "data = tifffile.imread(path_to_data / \"image_isotropized_enhanced.tif\")\n",
    "mask = tifffile.imread(path_to_data / \"mask_isotropized.tif\") # optional, read text above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643141b0",
   "metadata": {},
   "source": [
    "## Quick note about pre-processing\n",
    "\n",
    "The StarDist model we provide works best with roundish objects of approximately 15 pixels in diameters in all directions, and with images that have been normalized between 0 and 1.\n",
    "\n",
    "If your image already has the appropriate size and is normalized between 0 and 1, you can skip this and directly go to the prediction.\n",
    "\n",
    "To prepare your data, we recommend using the preprocessing notebook, particularly the following steps:\n",
    " - Adapting the image pixel size so that all objects are approximately 15 pixels in diameters in all directions using the `change_array_pixelsize` function. In our case, this meant resizing to the isotropic voxel size of (0.62, 0.62, 0.62) Âµm/pix. Do not hesitate to try different sizes on a subset of your data to optimize the result.\n",
    " - Normalizing the image values using `global_contrast_enhancement` or `local_contrast_enhancement`. Use the latter if your image is very deep, as it can improve performance in deeper planes by enhancing the contrast using local statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac4b72",
   "metadata": {},
   "source": [
    "For the purpose of this demo, the data we load has already been pre-processed, but in your case, you can go through the preprocessing notebook to prepare your data, or uncomment the following lines to run the pre-processing steps directly in this notebook if you are familiar with the functions already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76260a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_isotropized = change_array_pixelsize(\n",
    "#     data,\n",
    "#     input_pixelsize=..., # replace with the input pixelsize in ZYX order, e.g. (1, 0.5, 0.5)\n",
    "#     output_pixelsize=(0.621, 0.621, 0.621), # isotropic pixelsize\n",
    "#     order=1, # interpolation order, 1 for images, 0 for masks and labels\n",
    "# )\n",
    "# mask_isotropized = change_array_pixelsize(\n",
    "#     mask,\n",
    "#     input_pixelsize=..., # replace with the input pixelsize in ZYX order, e.g. (1, 0.5, 0.5)\n",
    "#     output_pixelsize=(0.621, 0.621, 0.621), # isotropic pixelsize\n",
    "#     order=0, # interpolation order, 1 for images, 0 for masks and labels\n",
    "# )\n",
    "\n",
    "# data_isotropized_normalized = local_contrast_enhancement(\n",
    "#     data_isotropized,\n",
    "#     mask=mask_isotropized,\n",
    "#     box_size=10,\n",
    "#     perc_low=1, perc_high=99\n",
    "# )\n",
    "\n",
    "data_isotropized_normalized = data # demo data is already preprocessed\n",
    "mask_isotropized = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a497ece",
   "metadata": {},
   "source": [
    "## Run the prediction using StarDist3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf85050",
   "metadata": {},
   "source": [
    "We provide the function `segment_stardist`, which can be used to detect nuclei in 3D images using the StarDist model. The folder containing the weights and config is automatically downloaded in this demo, and can also be found [here](https://zenodo.org/records/14748083)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stardist_model = Path(path_to_data / \"tapenade_stardist\") # folder containing weights\n",
    "\n",
    "labels = segment_stardist(\n",
    "    data_isotropized_normalized, # data already preprocessed\n",
    "    path_stardist_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e231d75",
   "metadata": {},
   "source": [
    "If you want to resize the labels back to the original pixel size, you can use the function `resize` from the package `skimage.transform`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_at_array_pixelsize = skimage.transform.resize(\n",
    "    labels,\n",
    "    data.shape,\n",
    "    anti_aliasing=False,\n",
    "    order=0,\n",
    "    preserve_range=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a2834",
   "metadata": {},
   "source": [
    "If you want to save the results, you can use the `tifffile.imwrite` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9edb5-a77f-4e43-a135-d2b1ecec1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite(..., labels) # replace ... with the path where you want to save the labels as a tif file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad967338",
   "metadata": {},
   "source": [
    "## Check results (napari required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import napari\n",
    "    viewer=napari.Viewer()\n",
    "    viewer.add_image(data_isotropized_normalized, colormap='inferno')\n",
    "    viewer.add_labels(labels)\n",
    "    napari.run()\n",
    "except ImportError:\n",
    "    print(\"Napari is not installed, skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a9b05c",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da84d5",
   "metadata": {},
   "source": [
    "### 1. Removing labels outside of mask (inside/outside of the tissue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca10224",
   "metadata": {},
   "source": [
    "Due to the presence of noise in the image, the segmentation can sometimes produce labels that are not fully contained in the mask. We provide the function `remove_labels_outside_of_mask` to remove these labels. It takes as input the labels and the mask, and removes the labels that are not fully contained in the mask.\n",
    "\n",
    "To create a mask of your image, use the preprocessing notebook or the napari plugin napari-tapenade-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3679bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered = remove_labels_outside_of_mask(\n",
    "    mask=mask_isotropized, \n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe7e0e",
   "metadata": {},
   "source": [
    "### 2 - Filter small volumes in the segmentation.\n",
    "\n",
    "First, plot the histogram of cell volumes to evaluate the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "props=regionprops(labels)\n",
    "volumes = np.array([prop.area for prop in props])\n",
    "\n",
    "plt.hist(volumes, bins=100)\n",
    "plt.title('Histogram of cell volumes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc7a5a",
   "metadata": {},
   "source": [
    "Then, remove the objects smaller than ```size_min```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece95ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the size to filter\n",
    "size_min = 400\n",
    "labels_filtered = remove_small_objects(labels,size_min)\n",
    "\n",
    "print('Before filtering :',len(np.unique(labels)),'labels \\nAfter filtering :',len(np.unique(labels_filtered)),'labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
