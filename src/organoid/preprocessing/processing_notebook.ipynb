{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import napari\n",
    "\n",
    "from organoid.preprocessing.preprocessing import (\n",
    "    make_array_isotropic,\n",
    "    compute_mask,\n",
    "    local_image_normalization,\n",
    "    align_array_major_axis,\n",
    "    crop_array_using_mask\n",
    ")\n",
    "from organoid.preprocessing.segmentation_postprocessing import (\n",
    "    remove_labels_outside_of_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Postprocessing Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents typical use cases of the preprocessing toolbox we provide in the `preprocessing.py` and `segmentation_postprocessing.py` scripts, and illustrates the use of function's parameters.\n",
    "\n",
    "All functions work on 3D (ZYX convention) or 4D (TZYX convention) images/labels/masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a raw image, a classical preprocessing pipeline would go through the following steps:\n",
    "1. **correcting for anisotropy**: dilate the image shape to make it isotropic.\n",
    "2. **computing the mask**: compute a boolean (0/1) mask of background/foreground voxels.\n",
    "3. **local image normalization**: normalize the image intensity in local regions of the image to make it more homogeneous.\n",
    "4. **image segmentation**: extract the objects of interest from the image, e.g with Stardist3D. ***NOT COVERED IN THIS NOTEBOOK***\n",
    "5. **spatio-temporal registration**: correct for object drift, or fuse two images spatially. ***NOT COVERED IN THIS NOTEBOOK***\n",
    "6. **forcing axis alignment**: specify axis to align the major axis of the objects to.\n",
    "7. **cropping array to mask**: crop any array (image, labels, or mask) to the smallest bounding box containing the mask.\n",
    "\n",
    "We also provide segmentation postprocessing functions:\n",
    "1. **removing labels outside of mask**: remove labels that are not fully contained in the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, specify if you wish to display each intermediate result in a Napari viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_in_napari = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = ...\n",
    "\n",
    "data = tifffile.imread(path_to_data)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer = napari.view_image(data, name='raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correcting for anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `make_array_isotropic` dilates the image shape to make it isotropic. It is useful when the image has a different resolution in the Z axis compared to the XY plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_array_isotropic in module organoid.preprocessing.preprocessing:\n",
      "\n",
      "make_array_isotropic(image: numpy.ndarray, zoom_factors: Tuple[float, float, float], order: int = 1, n_jobs: int = -1) -> numpy.ndarray\n",
      "    Resizes an input image to have isotropic voxel dimensions.\n",
      "    \n",
      "    Parameters:\n",
      "    - image: numpy array, input image\n",
      "    - zoom_factors: tuple of floats, zoom factors for each dimension\n",
      "    - order: int, order of interpolation for resizing (defaults to 1 for\n",
      "      linear interpolation). Choose 0 for nearest-neighbor interpolation\n",
      "      (e.g. for label images)\n",
      "    - n_jobs: int, optional number of parallel jobs for resizing (default: -1)\n",
      "    \n",
      "    Returns:\n",
      "    - resized_image: numpy array, resized image with isotropic voxel dimensions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_array_isotropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `zoom_factors` correspond to the amount of dilation to apply to each axis. For example, if `zoom_factors=(2.2, 0.9, 0.9)` the Z axis will be dilated by a factor of 2.2, and the XY plane will be compressed by a factor of 0.9. To make the voxel size isotropic and equal to one micrometer, `zoom_factors` can be set to the voxel size in micrometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4ec973a61947148d88f46fb988e29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making array isotropic:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isotropic_data = make_array_isotropic(data, zoom_factors=(1.6,1,1))\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(isotropic_data, name='isotropic data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the data isotropic, it is usually easier to visually identify a typical object size in the image, that will be useful to define parameters in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_mask` computes a boolean (0/1) mask of background/foreground voxels. It is useful to remove background noise and to define the region of interest for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function compute_mask in module organoid.preprocessing.preprocessing:\n",
      "\n",
      "compute_mask(image: numpy.ndarray, method: str, sigma_blur: float, threshold_factor: float = 1, compute_convex_hull: bool = False, n_jobs: int = -1) -> numpy.ndarray\n",
      "    Compute the mask for the given image using the specified method.\n",
      "    \n",
      "    Parameters:\n",
      "    - image: numpy array, input image\n",
      "    - method: str, method to use for thresholding. Can be 'snp' for Signal-Noise Product thresholding,\n",
      "      'otsu' for Otsu's thresholding, or 'histomin' for Histogram Minimum thresholding.\n",
      "    - sigma_blur: float, standard deviation of the Gaussian blur. Should typically be\n",
      "      around 1/3 of the typical object diameter.\n",
      "    - threshold_factor: float, factor to multiply the threshold (default: 1)\n",
      "    - compute_convex_hull: bool, set to True to compute the convex hull of the mask. If set to\n",
      "      False, a hole-filling operation will be performed instead.\n",
      "    - n_jobs: int, number of parallel jobs to run (-1 for using all available CPUs)\n",
      "    \n",
      "    Returns:\n",
      "    - mask: numpy array, binary mask of the same shape as the input image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(compute_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `method` can be set to the following values:\n",
    "1. `otsu` computes the mask by first blurring the image with a Gaussian filter of size `sigma_blur` (which should be set to the typical object size if it is known) and then applying Otsu's thresholding method.\n",
    "2. `histomin` first blurs the image with a Gaussian filter of size `sigma_blur` and then uses the major minimum of the intensity histogram as the threshold.\n",
    "3. `snp` computes a local Signal-and-Noise Product map from the image by using a Gaussian filter of size `sigma_blur` and then using Otsu's thresholding method on the map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`snp` is usually the most robust method, but it is also the slowest. `otsu` is the fastest but can be sensitive to noise and large intensity variations among foreground objects. In case of doubt, it is recommended to try all methods and visually inspect the results. `compute_mask` also has a parameter `threshold_factor` that can be used to multiply the initial threshold value given by the methods above.\n",
    "\n",
    "`compute_mask` can also be called with the parameter `compute_convex_hull` to return the convex hull of the mask. This is particularly useful when artifactual holes remain in the mask, but it leads to less precise mask. When set to False (default), a simple hole-filling operation is performed on the mask.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560198409ed8438297bf822c924859fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Thresholding image:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1c74636d974e24bc82e61b1a6cb714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Thresholding image:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_otsu = compute_mask(isotropic_data, method='otsu', sigma_blur=object_size, threshold_factor=0.6)\n",
    "mask_snp = compute_mask(isotropic_data, method='snp', sigma_blur=object_size/2)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(mask_otsu, name='mask otsu')\n",
    "    viewer.add_image(mask_snp, name='mask snp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Local image normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct for intensity variations in the image, we provide the function `local_image_normalization`. It computes the intensity histogram in boxes of size `box_size` (which should be set to the typical object size if it is known) centered on the vertices of a uniform 3D grid spanning the image array. For each point, the `perc_low` and `perc_high` percentiles of the histogram are computed and interpolated on each voxel of the image. The image is then normalized to map the `perc_low` percentile to 0 and the `perc_high` percentile to 1. The image is finally clipped to the range [0, 1].\n",
    "\n",
    "The function has an optional parameter `mask` to specify a mask of the background/foreground voxels. If the mask is provided, values outside the mask are set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function local_image_normalization in module organoid.preprocessing.preprocessing:\n",
      "\n",
      "local_image_normalization(image: numpy.ndarray, box_size: int, perc_low: float, perc_high: float, mask: numpy.ndarray = None, n_jobs: int = -1) -> numpy.ndarray\n",
      "    Performs local image normalization on either a single image or a temporal stack of images.\n",
      "    Stretches the image histogram in local neighborhoods by remapping intesities in the range\n",
      "    [perc_low, perc_high] to the range [0, 1].\n",
      "    This helps to enhance the contrast and improve the visibility of structures in the image.\n",
      "    \n",
      "    Parameters:\n",
      "    - image: numpy array, input image or temporal stack of images\n",
      "    - box_size: int, size of the local neighborhood for normalization\n",
      "    - perc_low: float, lower percentile for intensity normalization\n",
      "    - perc_high: float, upper percentile for intensity normalization\n",
      "    - mask: numpy array, binary mask used to set the background to zero (optional)\n",
      "    - n_jobs: int, number of parallel jobs to use (not used currently as the function is parallelized internally)\n",
      "    \n",
      "    Returns:\n",
      "    - image_norm: numpy array, normalized image or stack of normalized images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(local_image_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.218902587890625\n",
      "Time to interpolate percentiles: 6.420618772506714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:  14%|█▍        | 1/7 [00:08<00:48,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.2257323265075684\n",
      "Time to interpolate percentiles: 1.0847623348236084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:  29%|██▊       | 2/7 [00:10<00:24,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.1947710514068604\n",
      "Time to interpolate percentiles: 1.1211128234863281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:  43%|████▎     | 3/7 [00:13<00:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.1862375736236572\n",
      "Time to interpolate percentiles: 1.1524991989135742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:  57%|█████▋    | 4/7 [00:16<00:10,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.235020637512207\n",
      "Time to interpolate percentiles: 1.1151149272918701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:  71%|███████▏  | 5/7 [00:19<00:06,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.2440309524536133\n",
      "Time to interpolate percentiles: 1.1526014804840088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization:  86%|████████▌ | 6/7 [00:21<00:03,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute percentiles: 1.2031464576721191\n",
      "Time to interpolate percentiles: 1.149733304977417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local normalization: 100%|██████████| 7/7 [00:24<00:00,  3.53s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "normalized_data = local_image_normalization(isotropic_data, mask=mask_snp,\n",
    "                                            box_size=object_size,\n",
    "                                            perc_low=1, perc_high=99)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(normalized_data, name='normalized data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we do not cover the image segmentation step in this notebook. We refer the reader to the Stardist3D notebook provided with this package.\n",
    "\n",
    "For the purpose of this notebook, we will directly load a pre-segmented array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tifffile.imread(f'{path_to_data}/fusion3_labels.tif')[:7]\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_labels(labels, name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatio-temporal registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we do not cover the spatio-temporal registration step in this notebook. We refer the reader to the `spatial_registration` notebook provided with this package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forcing axis alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the object of interest (e.g a gastruloid) has a preferential orientation, it can be useful to align the major axis of the objects to a specific axis. We provide the function `align_array_major_axis` to do so. It computes the principal axes of the mask and rotates the image, labels, or mask to align the major axis to the specified axis.\n",
    "\n",
    "All three arrays can be given at the same time, or only a combinations of two of them (containing the mask) can be given. The major axis is aligned with axis `target_axis` (can be 'X', 'Y', or 'Z') by rotating the image in the plane `rotation_plane` (can be 'XY', 'XZ', or 'YZ').\n",
    "If the data is temporal (i.e 4D), the major axis is computed on a mask obtained by summing the 3D masks along the time axis. If only a specific time range is to be used to compute the major axis, the parameter `temporal_slice` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function align_array_major_axis in module organoid.preprocessing.preprocessing:\n",
      "\n",
      "align_array_major_axis(target_axis: str, rotation_plane: str, mask: numpy.ndarray, image: Optional[numpy.ndarray] = None, labels: Optional[numpy.ndarray] = None, order: int = 1, temporal_slice: Optional[int] = None, n_jobs: int = -1) -> Union[numpy.ndarray, Tuple[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]\n",
      "    Aligns the major axis of an array to a target axis in a specified rotation plane.\n",
      "    This function uses Principal Component Analysis (PCA) to determine the major axis of the array,\n",
      "    and then rotates the array to align the major axis with the target axis.\n",
      "    \n",
      "    Parameters:\n",
      "    - target_axis: str, the target axis to align the major axis with ('X', 'Y', or 'Z')\n",
      "    - rotation_plane: str, the rotation plane to perform the rotation in ('XY', 'XZ', or 'YZ')\n",
      "    - mask: numpy array, binary mask indicating the region of interest\n",
      "    - image: numpy array, input image or temporal stack of images (optional)\n",
      "    - labels: numpy array, labels corresponding to the mask (optional)\n",
      "    - order: int, order of interpolation for image rotation (default: 1)\n",
      "    - temporal_slice: int, optional temporal slicing applied to the mask before computing its major axis (default: None)\n",
      "    - n_jobs: int, number of parallel jobs to use (-1 for all available CPUs, 1 for sequential execution) (default: -1)\n",
      "    \n",
      "    Returns:\n",
      "    - If both image and labels are provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "        - image_rotated: numpy array, rotated image\n",
      "        - labels_rotated: numpy array, rotated labels\n",
      "    - If only image is provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "        - image_rotated: numpy array, rotated image\n",
      "    - If only labels is provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "        - labels_rotated: numpy array, rotated labels\n",
      "    - If neither image nor labels is provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(align_array_major_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921cd3c0f3b240a79a3565375e7103f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning mask:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3d33a6f4444495862e5def203ae1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning image:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321437a6fca54037a938b87406a10968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning labels:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aligned_mask, aligned_data, align_labels = align_array_major_axis(\n",
    "    target_axis='X', rotation_plane='XY', # -> align the major axis with the X axis\n",
    "    mask=mask_snp, image=normalized_data, labels=labels,\n",
    "    temporal_slice=slice(2, 10) # -> use the frames from time 2 to 10 to compute the major axis\n",
    ")\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(aligned_mask, name='aligned mask')\n",
    "    viewer.add_image(aligned_data, name='aligned data')\n",
    "    viewer.add_labels(align_labels, name='aligned labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cropping array to mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `crop_array_using_mask` crops any array (image, labels, or mask) to the smallest bounding box containing the mask. It has an optional parameter `margin` to add a margin around the bounding box.\n",
    "\n",
    "This function can be used to drastically reduce the size of the data to process at each stage by removing useless background voxels. **Though presented at the very end of the pipeline, it can be used at any stage of the pipeline to reduce the size of the data to process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function crop_array_using_mask in module organoid.preprocessing.preprocessing:\n",
      "\n",
      "crop_array_using_mask(mask: numpy.ndarray, image: Optional[numpy.ndarray] = None, labels: Optional[numpy.ndarray] = None, margin: int = 0, n_jobs: int = -1) -> Union[numpy.ndarray, Tuple[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]\n",
      "    Crop an array using a binary mask. If the array is temporal, the cropping\n",
      "    slice is computed by aggregating mask instances at all times.\n",
      "    \n",
      "    Parameters:\n",
      "    - mask: numpy array, binary mask indicating the region of interest\n",
      "    - image: numpy array, input image or temporal stack of images (optional)\n",
      "    - labels: numpy array, labels corresponding to the mask (optional)\n",
      "    - margin: int, optional margin to add around the mask (default: 0)\n",
      "    - n_jobs: int, number of parallel jobs to use (not used currently as the function is not computationally intensive)\n",
      "    \n",
      "    Returns:\n",
      "    - cropped_array: numpy array, cropped array based on the mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(crop_array_using_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_mask, cropped_data, cropped_labels = crop_array_using_mask(\n",
    "    mask=aligned_mask, image=aligned_data, labels=align_labels, margin=0\n",
    ")\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(cropped_mask, name='cropped mask')\n",
    "    viewer.add_image(cropped_data, name='cropped data')\n",
    "    viewer.add_labels(cropped_labels, name='cropped labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Removing labels outside of mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the presence of noise in the image, the segmentation can sometimes produce labels that are not fully contained in the mask. We provide the function `remove_labels_outside_of_mask` to remove these labels. It takes as input the labels and the mask, and removes the labels that are not fully contained in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d6e46c63374ab58767de092bd27e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing labels outside of mask:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_filtered = remove_labels_outside_of_mask(cropped_labels, cropped_mask)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_labels(labels_filtered, name='labels filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
