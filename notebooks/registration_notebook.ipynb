{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed08f86b",
   "metadata": {},
   "source": [
    "# Registration Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from organoid import preprocessing\n",
    "from organoid import reconstruction\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a28c3",
   "metadata": {},
   "source": [
    "If you have xml files with the locations of multipositions, you can input them here to plot the positions of all samples and associate the order form the 2 views (in case they are not acquired in the same order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ref_positions= ... #xml file\n",
    "path_float_positions= ...\n",
    "\n",
    "reconstruction.plot_positions(path_ref_positions=path_ref_positions,path_float_positions=path_float_positions)\n",
    "ordered_numbers_ref,ordered_numbers_float=reconstruction.associate_positions(\n",
    "      path_ref_positions=path_ref_positions,\n",
    "    path_float_positions=path_float_positions\n",
    ")\n",
    "print(ordered_numbers_ref,ordered_numbers_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b1262",
   "metadata": {},
   "source": [
    "Give the path to your data and name of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4473c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you did not use the function associate_top_bottom, you can define the list_ref and list_float manually,\n",
    "#for example if you have one sample and 2 views : list_ref=['view1'] and list_float=['view2']\n",
    "#or with 2 samples and 2 views : list_ref=['01','02'] and list_float=['03','04'] with 01 and 03 the bottom and top views of sample 1\n",
    "\n",
    "#Below you generate automatically the list_ref and list_float from the number paired above, bottom with top\n",
    "# list_ref = [\"{:01d}_view1\".format(i) for i in ordered_numbers_ref]\n",
    "# list_float = [\"{:01d}_view2\".format(i) for i in ordered_numbers_float]\n",
    "\n",
    "list_ref = []\n",
    "list_float = []\n",
    "channels = [\n",
    "\"hoechst\",\n",
    "'ecad',\n",
    "'oct4',\n",
    "'sox2'\n",
    "]  # example of channels. If you have only one channel, just put one element in the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b5bdb",
   "metadata": {},
   "source": [
    "Create the folder structure necessary for the registration. All files, reference and float, need to be in the same folder, folder_experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575de57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction.create_folders(\n",
    "    folder_experiment= ...,\n",
    "    list_ref=list_ref, list_float=list_float, channels=channels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44eaa2b",
   "metadata": {},
   "source": [
    "Register automatically\n",
    "\n",
    "To register your floating image onto the reference one, you should have an idea of the transformation to apply.  From this approximative initial transformation, the algorithm will find the exact transformation to match the 2 sides.\n",
    "\n",
    "If your image has multiple channels, one will be the reference one, registered first. The second part of the code executes the registration for the other channels, using the same transformation as computed for the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, we consider only one sample. If you have multiple samples, you can loop : list_ref[i]\n",
    "path= ...\n",
    "i = 0 #index of sample\n",
    "filename_ref = list_ref[i]\n",
    "filename_float = list_float[i]\n",
    "input_voxel = [0.6,0.6,1] #voxel size (XYZ)\n",
    "output_voxel = [0.6,0.6,1]\n",
    "channel_reference = \"hoechst\"  #ubiquitous channel\n",
    "\n",
    "#if you have a first idea of your tranformations (rotation, translation), you can input them here:\n",
    "rot=[180,0,0] #XYZ in degrees\n",
    "trans2= [0,0,0] #XYZ\n",
    "\n",
    "reconstruction.register(\n",
    "    path_data=Path(path) / filename_ref / \"raw\",\n",
    "    path_transformation=Path(path) / filename_ref / \"trsf\",\n",
    "    path_registered_data=Path(path) / filename_ref / \"registered\",\n",
    "    reference_image=f\"{filename_ref}_{channel_reference}.tif\",\n",
    "    floating_image=f\"{filename_float}_{channel_reference}.tif\",\n",
    "    input_voxel=input_voxel,\n",
    "    output_voxel=output_voxel,\n",
    "    compute_trsf=1,\n",
    "    # example of transformation if the sample has been flipped between the 2 views.\n",
    "    # trans1 is a translation before the rotation, trans2 is a translation after the rotation.\n",
    "    # trans1=trans1,  #trans1 is a translation before the rotation whereas trans2 is a translation after the rotation\n",
    "    rot=rot,\n",
    "    trans2=trans2,\n",
    "    test_init=0, #if you want to apply only the initial transformation to check is it makes sense, set to 1\n",
    "    # input_init_trsf_from_plugin=rf'..\\initial_transformation.json', #path of the json file saved from the plugin\n",
    "    trsf_type=\"rigid\",\n",
    "    depth=3,\n",
    "    bbox=1,\n",
    "    save_json=Path(path) / filename_ref, #to save all parameters\n",
    ")\n",
    "\n",
    "#applying the same transformation to the other channels\n",
    "for channel in channels :\n",
    "    if channel != channel_reference:\n",
    "        reconstruction.register(\n",
    "            path_data=Path(path) / filename_ref / \"raw\",\n",
    "            path_transformation =Path(path) / filename_ref / \"trsf\",\n",
    "            path_registered_data=Path(path) / filename_ref / \"registered\",\n",
    "            reference_image=f\"{filename_ref}_{channel}.tif\",\n",
    "            floating_image=f\"{filename_float}_{channel}.tif\",\n",
    "            input_voxel=input_voxel,\n",
    "            output_voxel=output_voxel,\n",
    "            compute_trsf=0,\n",
    "            trsf_type=\"rigid\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a47ef",
   "metadata": {},
   "source": [
    "Napari visualization (you need to have napari installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=channel_reference #by default, we visualize using the reference channel but you can replace it here by : 'ecad', 'bra',...\n",
    "image = tifffile.imread(Path(path) / f\"{filename_ref}\" / 'registered' / f\"{filename_float}_{channel}.tif\" )\n",
    "scale = (output_voxel[2], output_voxel[1], output_voxel[0])\n",
    "reconstruction.check_napari(\n",
    "    folder=Path(path) / f\"{filename_ref}\",\n",
    "    reference_image=f\"{filename_ref}_{channel}.tif\",\n",
    "    floating_image=f\"{filename_float}_{channel}.tif\",\n",
    "    scale=scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d890c",
   "metadata": {},
   "source": [
    "Fuse the 2 registered sides into one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in channels:\n",
    "    image = reconstruction.fuse_sides(\n",
    "        path_registered_data=Path(path) / filename_ref / \"registered\",\n",
    "        reference_image_reg=f\"{filename_ref}_{ch}.tif\",\n",
    "        floating_image_reg=f\"{filename_float}_{ch}.tif\",\n",
    "        folder_output=Path(path) / filename_ref / \"fused\",\n",
    "        name_output=rf\"fused_data_{ch}.tif\",\n",
    "        slope_coeff=20,  # slope of the weight profile : 5 corresponds to a low slope, wide fusion width and 25 to a strong slope, very thin fusion width.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813afe5",
   "metadata": {},
   "source": [
    "Merge all the channels in one multichannel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the images should be named 'sampleid_channel.tif', eg 'fuseddata_dapi.tif', this depends on the argument \"name_output\" above.\n",
    "reconstruction.write_hyperstacks(\n",
    "    path=Path(path) / filename_ref / \"fused\",\n",
    "    sample_id=\"fused_data\",\n",
    "    channels=channels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889bc65d",
   "metadata": {},
   "source": [
    "Optional : Manual registration without Napari\n",
    "\n",
    "If the automatic registration is not satisfying, one option is to give more precise initial transformations to the algorithm.\n",
    "\n",
    "For that, you need to define landmarks, ie features that you recognize in both the reference image and the floating image, that you will need to pinpoint with a marker of given label, this label has to be an integer that has the same value in both image.\n",
    "\n",
    "Once you have at least 3 annotated landmarks (=3 labels in each image) in a tif image, input them below.\n",
    "If the result seems good, you can input the initial transformations above ('Register automatically)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa40381",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ...\n",
    "filename_ref = ...\n",
    "filename_float = ...\n",
    "input_voxel = ...\n",
    "output_voxel = input_voxel\n",
    "\n",
    "path_to_landmarks = ...\n",
    "reference_landmarks = tifffile.imread(\n",
    "    Path(path_to_landmarks) / f\"ref.tif\"\n",
    ")\n",
    "floating_landmarks = tifffile.imread(\n",
    "    Path(path_to_landmarks) / f\"float.tif\"\n",
    ")\n",
    "reference_landmarks = reference_landmarks.astype(np.uint16)\n",
    "floating_landmarks = floating_landmarks.astype(np.uint16)\n",
    "channel = \"dapi\"\n",
    "\n",
    "rot, trans1, trans2 = reconstruction.manual_registration_fct(\n",
    "    reference_landmarks=reference_landmarks,\n",
    "    floating_landmarks=floating_landmarks,\n",
    "    scale=(input_voxel[2], input_voxel[1], input_voxel[0]),\n",
    ")\n",
    "rot=[rot[2],rot[1],rot[0]]\n",
    "\n",
    "reconstruction.register(\n",
    "    path_data=Path(path) / filename_ref / \"raw\",\n",
    "    path_transformation=Path(path) / filename_ref / \"trsf\",\n",
    "    path_registered_data=Path(path) / filename_ref / \"registered\",\n",
    "    reference_image=f\"{filename_ref}_{channel}.tif\",\n",
    "    floating_image=f\"{filename_float}_{channel}.tif\",\n",
    "    input_voxel=input_voxel,  \n",
    "    output_voxel=output_voxel,\n",
    "    compute_trsf=1,\n",
    "    rot=rot,\n",
    "    trans1=trans1,\n",
    "    trans2=trans2,\n",
    "    test_init=0,\n",
    "    trsf_type=\"rigid\",\n",
    "    depth=3,\n",
    "    bbox=1,\n",
    "    save_json=\"\",\n",
    ")\n",
    "\n",
    "print('rot = ',rot,'\\ntrans1=',trans1,'\\ntrans2=',trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9ba49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
