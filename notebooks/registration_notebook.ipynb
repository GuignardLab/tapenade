{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed08f86b",
   "metadata": {},
   "source": [
    "# Registration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a729771",
   "metadata": {},
   "source": [
    "### <font color='red'> After clicking on a code cell, press \"Shift+Enter\" to run the code, or click on the \"Run\" button in the toolbar above.<br>\n",
    "\n",
    "### Replace \"...\" signs with the appropriate path to your data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87934e1",
   "metadata": {},
   "source": [
    "Folder structure : for each sample, 2 tif files, one for each view, with different names and located in the same folder.\n",
    "Datatype should be int16,uint16 or float32, otherwise no output will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from organoid import reconstruction\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a28c3",
   "metadata": {},
   "source": [
    "If you have xml files with the locations of multipositions, you can input them here to plot the positions of all samples and associate the order form the 2 views (in case they are not acquired in the same order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ref_positions= ...\n",
    "path_float_positions= ...\n",
    "\n",
    "reconstruction.plot_positions(path_ref_positions=path_ref_positions,path_float_positions=path_float_positions)\n",
    "ordered_numbers_ref,ordered_numbers_float=reconstruction.associate_positions(\n",
    "      path_ref_positions=path_ref_positions,\n",
    "    path_float_positions=path_float_positions\n",
    ")\n",
    "print(ordered_numbers_ref,ordered_numbers_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b1262",
   "metadata": {},
   "source": [
    "Give the path to your data and name of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4473c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you did not use the function associate_top_bottom, you can define the list_ref and list_float manually,\n",
    "#for example if you have one sample and 2 views : list_ref=['view1'] and list_float=['view2']\n",
    "#or with 2 samples and 2 views : list_ref=['01','02'] and list_float=['03','04'] with 01 and 03 the bottom and top views of sample 1\n",
    "\n",
    "#Below you generate automatically the list_ref and list_float from the number paired above, bottom with top\n",
    "# list_ref = [\"{:01d}_view1\".format(i) for i in ordered_numbers_ref]\n",
    "# list_float = [\"{:01d}_view2\".format(i) for i in ordered_numbers_float]\n",
    "\n",
    "list_ref = []\n",
    "list_float = []\n",
    "channels = [\n",
    "\"hoechst\",\n",
    "'ecad',\n",
    "'bra',\n",
    "'sox2'\n",
    "]  # example of channels. If you have only one channel, just put one element in the list\n",
    "\n",
    "#path where you have your data saved\n",
    "folder_experiment = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b5bdb",
   "metadata": {},
   "source": [
    "Create the folder structure necessary for the registration. All files, reference and float, need to be in the same folder, folder_experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575de57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction.create_folders(\n",
    "    folder_experiment= folder_experiment,\n",
    "    list_ref=list_ref, list_float=list_float, channels=channels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44eaa2b",
   "metadata": {},
   "source": [
    "Register automatically\n",
    "\n",
    "To register your floating image onto the reference one, you should have an idea of the transformation to apply.  From this approximative initial transformation, the algorithm will find the exact transformation to match the 2 sides.\n",
    "\n",
    "If your image has multiple channels, one will be the reference one, registered first. The second part of the code executes the registration for the other channels, using the same transformation as computed for the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, we consider only one sample. If you have multiple samples, you can loop : list_ref[i]\n",
    "i = 0 #index of sample\n",
    "filename_ref = list_ref[i]\n",
    "filename_float = list_float[i]\n",
    "input_voxel = [0.6,0.6,1] #voxel size (XYZ)\n",
    "output_voxel = [1,1,1]\n",
    "channel_reference = \"hoechst\"  #ubiquitous channel\n",
    "\n",
    "# #if you have a first idea of your tranformations (rotation, translation), you can input them here:\n",
    "rot=[180,0,0] #XYZ in degrees\n",
    "trans2= [0,0,0] #XYZ\n",
    "\n",
    "reconstruction.register(\n",
    "    path_data=Path(folder_experiment) / filename_ref / \"raw\",\n",
    "    path_transformation=Path(folder_experiment) / filename_ref / \"trsf\",\n",
    "    path_registered_data=Path(folder_experiment) / filename_ref / \"registered\",\n",
    "    reference_image=f\"{filename_ref}_{channel_reference}.tif\",\n",
    "    floating_image=f\"{filename_float}_{channel_reference}.tif\",\n",
    "    input_voxel=input_voxel,\n",
    "    output_voxel=output_voxel,\n",
    "    compute_trsf=1,\n",
    "    # example of transformation if the sample has been flipped between the 2 views.\n",
    "    # trans1 is a translation before the rotation, trans2 is a translation after the rotation.\n",
    "    # trans1=trans1,  #trans1 is a translation before the rotation whereas trans2 is a translation after the rotation\n",
    "    rot=rot,\n",
    "    # trans2=trans2,\n",
    "    test_init=0, #if you want to apply only the initial transformation to check is it makes sense, set to 1\n",
    "    # input_init_trsf_from_plugin=rf'C:\\Users\\gros\\Desktop\\DATA\\reg_test\\initial_transformation.json', #path of the json file saved from the plugin\n",
    "    trsf_type=\"rigid\",\n",
    "    depth=3,\n",
    "    bbox=1,\n",
    "    save_json=Path(folder_experiment) / filename_ref, #to save all parameters\n",
    ")\n",
    "\n",
    "# #applying the same transformation to the other channels\n",
    "for channel in channels :\n",
    "    if channel != channel_reference:\n",
    "        reconstruction.register(\n",
    "            path_data=Path(folder_experiment) / filename_ref / \"raw\",\n",
    "            path_transformation =Path(folder_experiment) / filename_ref / \"trsf\",\n",
    "            path_registered_data=Path(folder_experiment) / filename_ref / \"registered\",\n",
    "            reference_image=f\"{filename_ref}_{channel}.tif\",\n",
    "            floating_image=f\"{filename_float}_{channel}.tif\",\n",
    "            input_voxel=input_voxel,\n",
    "            output_voxel=output_voxel,\n",
    "            compute_trsf=0,\n",
    "            trsf_type=\"rigid\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a47ef",
   "metadata": {},
   "source": [
    "Napari visualization (you need to have napari installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel=channel_reference #by default, we visualize using the reference channel but you can replace it here by : 'ecad', 'bra',...\n",
    "scale = (output_voxel[2], output_voxel[1], output_voxel[0])\n",
    "reconstruction.check_napari(\n",
    "    folder=Path(folder_experiment)/ f\"{filename_ref}\",\n",
    "    reference_image=f\"{filename_ref}_{channel}.tif\",\n",
    "    floating_image=f\"{filename_float}_{channel}.tif\",\n",
    "    scale=scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ed98f",
   "metadata": {},
   "source": [
    "If it looks well registered, you can now fuse the 2 sides together and fuse the channels to create your new multichannel image.\n",
    "\n",
    "If you are not satisfied with the registration, adjust the initial transformations (rot, trans1, trans2), you can use the plugin napari-manual-registration to ensure giving accurate input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, we consider only one sample. If you have multiple samples, you can loop : list_ref[i]\n",
    "i = 0 #index of sample\n",
    "filename_ref = list_ref[i]\n",
    "filename_float = list_float[i]\n",
    "\n",
    "for ch in channels:\n",
    "    image = reconstruction.fuse_sides(\n",
    "        path_registered_data=Path(folder_experiment) / filename_ref / \"registered\",\n",
    "        reference_image_reg=f\"{filename_ref}_{ch}.tif\",\n",
    "        floating_image_reg=f\"{filename_float}_{ch}.tif\",\n",
    "        folder_output=Path(folder_experiment) / filename_ref / \"fused\",\n",
    "        name_output=rf\"fused_data_{ch}.tif\",\n",
    "        slope_coeff=20 # slope of the weight profile : 5 corresponds to a low slope, wide fusion width and 25 to a strong slope, very thin fusion width.\n",
    "    )\n",
    "\n",
    "#the result is saved channel by channel in the folder 'fused'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6813afe5",
   "metadata": {},
   "source": [
    "Merge all the channels in one multichannel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, we consider only one sample. If you have multiple samples, you can loop : list_ref[i]\n",
    "i = 0 #index of sample\n",
    "filename_ref = list_ref[i]\n",
    "filename_float = list_float[i]\n",
    "\n",
    "# the images should be named 'sampleid_channel.tif', eg 'fuseddata_dapi.tif', this depends on the argument \"name_output\" above.\n",
    "reconstruction.write_hyperstacks(\n",
    "    path=Path(folder_experiment) / filename_ref / \"fused\",\n",
    "    sample_id=\"fused_data\",\n",
    "    channels=channels\n",
    ")\n",
    "#the result is saved under the name 'sample_id'_registered.tif in the folder 'fused'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889bc65d",
   "metadata": {},
   "source": [
    "# Optional : Manual registration without Napari\n",
    "\n",
    "If the automatic registration is not satisfying, one option is to give more precise initial transformations to the algorithm.\n",
    "\n",
    "For that, you need to define landmarks, ie features that you recognize in both the reference image and the floating image, that you will need to pinpoint with a marker of given label, this label has to be an integer that has the same value in both image.\n",
    "\n",
    "Once you have at least 3 annotated landmarks (=3 labels in each image) in a tif image, input them below.\n",
    "If the result seems good, you can input the initial transformations above ('Register automatically)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa40381",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ...\n",
    "filename_ref = ...\n",
    "filename_float = ...\n",
    "input_voxel = ...\n",
    "output_voxel = input_voxel\n",
    "\n",
    "path_to_landmarks = ...\n",
    "reference_landmarks = tifffile.imread(\n",
    "    Path(path_to_landmarks) / f\"ref.tif\"\n",
    ")\n",
    "floating_landmarks = tifffile.imread(\n",
    "    Path(path_to_landmarks) / f\"float.tif\"\n",
    ")\n",
    "reference_landmarks = reference_landmarks.astype(np.uint16)\n",
    "floating_landmarks = floating_landmarks.astype(np.uint16)\n",
    "channel = \"dapi\"\n",
    "\n",
    "rot, trans1, trans2 = reconstruction.manual_registration_fct(\n",
    "    reference_landmarks=reference_landmarks,\n",
    "    floating_landmarks=floating_landmarks,\n",
    "    scale=(input_voxel[2], input_voxel[1], input_voxel[0]),\n",
    ")\n",
    "rot=[rot[2],rot[1],rot[0]]\n",
    "\n",
    "reconstruction.register(\n",
    "    path_data=Path(path) / filename_ref / \"raw\",\n",
    "    path_transformation=Path(path) / filename_ref / \"trsf\",\n",
    "    path_registered_data=Path(path) / filename_ref / \"registered\",\n",
    "    reference_image=f\"{filename_ref}_{channel}.tif\",\n",
    "    floating_image=f\"{filename_float}_{channel}.tif\",\n",
    "    input_voxel=input_voxel,  \n",
    "    output_voxel=output_voxel,\n",
    "    compute_trsf=1,\n",
    "    rot=rot,\n",
    "    trans1=trans1,\n",
    "    trans2=trans2,\n",
    "    test_init=0,\n",
    "    trsf_type=\"rigid\",\n",
    "    depth=3,\n",
    "    bbox=1,\n",
    "    save_json=\"\",\n",
    ")\n",
    "\n",
    "print('rot = ',rot,'\\ntrans1=',trans1,'\\ntrans2=',trans2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
