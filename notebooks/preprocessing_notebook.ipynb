{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Postprocessing Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> After clicking on a cell, press \"Shift+Enter\" to run the code, or click on the \"Run\" button in the toolbar above.<br>\n",
    "\n",
    "### Replace \"...\" signs with the appropriate path to your data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "try:\n",
    "    import napari\n",
    "    napari_available = True\n",
    "except ImportError:\n",
    "    print(\"Napari is not installed. Some parts of the notebook will not be available.\")\n",
    "    napari_available = False\n",
    "\n",
    "from tapenade.preprocessing import (\n",
    "    change_array_pixelsize,\n",
    "    compute_mask,\n",
    "    global_contrast_enhancement,\n",
    "    local_contrast_enhancement,\n",
    "    align_array_major_axis,\n",
    "    crop_array_using_mask\n",
    ")\n",
    "from tapenade.preprocessing.segmentation_postprocessing import (\n",
    "    remove_labels_outside_of_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents typical use cases of the preprocessing toolbox we provide in the `preprocessing.py` and `segmentation_postprocessing.py` scripts, and illustrates the use of function's parameters.\n",
    "\n",
    "All functions work on 3D (ZYX convention) or 4D (TZYX convention) images/labels/masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a raw image, a classical preprocessing pipeline would go through the following steps:\n",
    "1. **correcting for anisotropy**: dilate the image shape to make it isotropic.\n",
    "2. **computing the mask**: compute a boolean (0/1) mask of background/foreground voxels.\n",
    "3. **image contrast enhancement**: enhance the contrast of the image either globally or in local regions of the image to make it more homogeneous.\n",
    "4. **image segmentation**: extract the objects of interest from the image, e.g with Stardist3D. ***NOT COVERED IN THIS NOTEBOOK***\n",
    "5. **spatio-temporal registration**: correct for object drift, or fuse two images spatially. ***NOT COVERED IN THIS NOTEBOOK***\n",
    "6. **forcing axis alignment**: specify axis to align the major axis of the objects to.\n",
    "7. **cropping array to mask**: crop any array (image, labels, or mask) to the smallest bounding box containing the mask.\n",
    "\n",
    "We also provide segmentation postprocessing functions:\n",
    "1. **removing labels outside of mask**: remove labels that are not fully contained in the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, specify if you wish to display each intermediate result in a Napari viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_in_napari = True\n",
    "\n",
    "# The final value of display_in_napari depends on whether napari is installed\n",
    "display_in_napari = display_in_napari and napari_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = ...\n",
    "\n",
    "data = tifffile.imread(path_to_data)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer = napari.view_image(data, name='raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correcting for anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `change_array_pixelsize` dilates the image shape to make it isotropic. It is useful when the image has a different resolution in the Z axis compared to the XY plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(change_array_pixelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we illustrate how to convert the pixelsize of the data from (1, 0.62, 0.62) µm/pix, to (0.62, 0.62, 0.62) µm/pix to make the image isotropic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isotropic_data = change_array_pixelsize(array=data, input_pixelsize=(1, 0.62, 0.62),\n",
    "                                         output_pixelsize=(0.62,0.62,0.62))\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(isotropic_data, name='isotropic data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the data isotropic, it is usually easier to visually identify a typical object size in the image, that will be useful to define parameters in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_mask` computes a boolean (0/1) mask of background/foreground voxels. It is useful to remove background noise and to define the region of interest for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(compute_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `method` can be set to the following values:\n",
    "1. `otsu` computes the mask by first blurring the image with a Gaussian filter of size `sigma_blur` (which should be set to the typical object size if it is known) and then applying Otsu's thresholding method.\n",
    "2. `snp otsu` computes a local Signal-and-Noise Product map from the image by using a Gaussian filter of size `sigma_blur` and then using Otsu's thresholding method on the map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`snp otsu` is usually the most robust method, but it is also the slowest. `otsu` is the fastest but can be sensitive to noise and large intensity variations among foreground objects. In case of doubt, it is recommended to try all methods and visually inspect the results. `compute_mask` also has a parameter `threshold_factor` that can be used to multiply the initial threshold value given by the methods above.\n",
    "\n",
    "`compute_mask` can also be called with the parameter `compute_convex_hull` to return the convex hull of the mask. This is particularly useful when artifactual holes remain in the mask, but it leads to less precise mask, and the computation takes way longer. When set to False (default), a simple hole-filling operation is performed on the mask.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_otsu = compute_mask(isotropic_data, method='otsu', sigma_blur=object_size, threshold_factor=0.6)\n",
    "mask_snp = compute_mask(isotropic_data, method='snp otsu', sigma_blur=object_size/2)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(mask_otsu, name='mask otsu')\n",
    "    viewer.add_image(mask_snp, name='mask snp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image contrast enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct for intensity variations in the image, we provide the functions `global_contrast_enhancement` and `local_contrast_enhancement`.\n",
    "\n",
    "`global_contrast_enhancement` applies a linear mapping on the image so that the `perc_low` percentile is mapped to 0 and the `perc_high` percentile is mapped to 1. The image is finally clipped to the range [0, 1]. This function is useful when the image has long tails in the intensity histogram, i.e when there are very bright or very dark objects in the image, which lead to a poor contrast. Outliers can be removed by setting `perc_low` and `perc_high` to a value between 0 and 100.\n",
    "\n",
    "`local_contrast_enhancement` computes the intensity histogram in boxes of size `box_size` (which should be set to the typical object size if it is known) centered on the vertices of a uniform 3D grid spanning the image array. For each point, the `perc_low` and `perc_high` percentiles of the histogram are computed and interpolated on each voxel of the image. The image intensity is then linearly mapped so that `perc_low` percentile maps to 0 and the `perc_high` percentile maps to 1. The image is finally clipped to the range [0, 1]. This function is useful when the image has a non-uniform illumination, i.e when the intensity varies across the image, which leads to contrast variations across space.\n",
    "\n",
    "The functions have an optional parameter `mask` to specify a mask of the background/foreground voxels. If a mask is provided, values outside the mask are set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(global_contrast_enhancement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(local_contrast_enhancement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_data_global = global_contrast_enhancement(isotropic_data, mask=mask_snp, \n",
    "                                                  perc_low=1, perc_high=99)\n",
    "\n",
    "# in the rest of the notebook, we will use the locally enhanced data\n",
    "enhanced_data = local_contrast_enhancement(isotropic_data, mask=mask_snp,\n",
    "                                            box_size=object_size,\n",
    "                                            perc_low=1, perc_high=99)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(enhanced_data_global, name='enhanced data global')\n",
    "    viewer.add_image(enhanced_data, name='enhanced data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we do not cover the image segmentation step in this notebook. We refer the reader to the `segmentation` notebook provided with this package, which uses Stardist3D to detect nuclei.\n",
    "\n",
    "For the purpose of this notebook, we will directly load a pre-segmented array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_labels = ...\n",
    "\n",
    "labels = tifffile.imread(path_to_labels)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_labels(labels, name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatio-temporal registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we do not cover the spatio-temporal registration step in this notebook. We refer the reader to the `registration` notebook provided with this package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forcing axis alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the object of interest (e.g a gastruloid) has a preferential orientation, it can be useful to align the major axis of the objects to a specific axis. We provide the function `align_array_major_axis` to do so. It computes the principal axes of the mask and rotates the image, labels, or mask to align the major axis to the specified axis.\n",
    "\n",
    "All three arrays can be given at the same time, or only a combinations of two of them (containing the mask) can be given. The major axis is aligned with axis `target_axis` (can be 'X', 'Y', or 'Z') by rotating the image in the plane `rotation_plane` (can be 'XY', 'XZ', or 'YZ').\n",
    "If the data is temporal (i.e 4D), the major axis is computed on a mask obtained by summing the 3D masks along the time axis. If only a specific time range is to be used to compute the major axis, the parameter `temporal_slice` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(align_array_major_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_labels = align_array_major_axis(\n",
    "    target_axis='X', rotation_plane='XY', # -> align the major axis with the X axis\n",
    "    mask=mask_snp, array=labels, order=0, # order 0 for labels and masks\n",
    "    temporal_slice=slice(2, 10) # -> use the frames from time 2 to 10 to compute the major axis\n",
    ")\n",
    "\n",
    "aligned_data = align_array_major_axis(\n",
    "    target_axis='X', rotation_plane='XY', # -> align the major axis with the X axis\n",
    "    mask=mask_snp, array=enhanced_data, order=1,\n",
    "    temporal_slice=slice(2, 10) # -> use the frames from time 2 to 10 to compute the major axis\n",
    ")\n",
    "\n",
    "aligned_mask = align_array_major_axis(\n",
    "    target_axis='X', rotation_plane='XY', # -> align the major axis with the X axis\n",
    "    mask=mask_snp, array=mask_snp, order=0, # order 0 for labels and masks\n",
    "    temporal_slice=slice(2, 10) # -> use the frames from time 2 to 10 to compute the major axis\n",
    ")\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(aligned_mask, name='aligned mask')\n",
    "    viewer.add_image(aligned_data, name='aligned data')\n",
    "    viewer.add_labels(align_labels, name='aligned labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cropping array to mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `crop_array_using_mask` crops any array (image, labels, or mask) to the smallest bounding box containing the mask. It has an optional parameter `margin` to add a margin around the bounding box.\n",
    "\n",
    "This function can be used to drastically reduce the size of the data to process at each stage by removing useless background voxels. **Though presented at the very end of the pipeline, it can be used at any stage of the pipeline to reduce the size of the data to process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(crop_array_using_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_labels = crop_array_using_mask(\n",
    "    mask=aligned_mask, array=align_labels, margin=0\n",
    ")\n",
    "\n",
    "cropped_data = crop_array_using_mask(\n",
    "    mask=aligned_mask, array=aligned_data, margin=0\n",
    ")\n",
    "\n",
    "cropped_mask = crop_array_using_mask(\n",
    "    mask=aligned_mask, array=aligned_mask, margin=0\n",
    ")\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(cropped_mask, name='cropped mask')\n",
    "    viewer.add_image(cropped_data, name='cropped data')\n",
    "    viewer.add_labels(cropped_labels, name='cropped labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Removing labels outside of mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the presence of noise in the image, the segmentation can sometimes produce labels that are not fully contained in the mask. We provide the function `remove_labels_outside_of_mask` to remove these labels. It takes as input the labels and the mask, and removes the labels that are not fully contained in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filtered = remove_labels_outside_of_mask(mask=cropped_mask, labels=cropped_labels)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_labels(labels_filtered, name='labels filtered')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
