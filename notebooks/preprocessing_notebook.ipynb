{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "try:\n",
    "    import napari\n",
    "    napari_available = True\n",
    "except ImportError:\n",
    "    print(\"Napari is not installed. Some parts of the notebook will not be available.\")\n",
    "    napari_available = False\n",
    "\n",
    "from tapenade.preprocessing import (\n",
    "    change_arrays_pixelsize,\n",
    "    compute_mask,\n",
    "    global_image_equalization,\n",
    "    local_image_equalization,\n",
    "    align_array_major_axis,\n",
    "    crop_array_using_mask\n",
    ")\n",
    "from tapenade.preprocessing.segmentation_postprocessing import (\n",
    "    remove_labels_outside_of_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> After clicking on a cell, press \"Shift+Enter\" to run the code, or click on the \"Run\" button in the toolbar above.<br>\n",
    "\n",
    "### Replace \"...\" signs with the appropriate path to your data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Postprocessing Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents typical use cases of the preprocessing toolbox we provide in the `preprocessing.py` and `segmentation_postprocessing.py` scripts, and illustrates the use of function's parameters.\n",
    "\n",
    "All functions work on 3D (ZYX convention) or 4D (TZYX convention) images/labels/masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a raw image, a classical preprocessing pipeline would go through the following steps:\n",
    "1. **correcting for anisotropy**: dilate the image shape to make it isotropic.\n",
    "2. **computing the mask**: compute a boolean (0/1) mask of background/foreground voxels.\n",
    "3. **image equalization**: equalize the image intensity either globally or in local regions of the image to make it more homogeneous.\n",
    "4. **image segmentation**: extract the objects of interest from the image, e.g with Stardist3D. ***NOT COVERED IN THIS NOTEBOOK***\n",
    "5. **spatio-temporal registration**: correct for object drift, or fuse two images spatially. ***NOT COVERED IN THIS NOTEBOOK***\n",
    "6. **forcing axis alignment**: specify axis to align the major axis of the objects to.\n",
    "7. **cropping array to mask**: crop any array (image, labels, or mask) to the smallest bounding box containing the mask.\n",
    "\n",
    "We also provide segmentation postprocessing functions:\n",
    "1. **removing labels outside of mask**: remove labels that are not fully contained in the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, specify if you wish to display each intermediate result in a Napari viewer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_in_napari = True\n",
    "\n",
    "# The final value of display_in_napari depends on whether napari is installed\n",
    "display_in_napari = display_in_napari and napari_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = ...\n",
    "\n",
    "data = tifffile.imread(path_to_data)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer = napari.view_image(data, name='raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correcting for anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `change_arrays_pixelsize` dilates the image shape to make it isotropic. It is useful when the image has a different resolution in the Z axis compared to the XY plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function change_arrays_pixelsize in module tapenade.preprocessing._preprocessing:\n",
      "\n",
      "change_arrays_pixelsize(mask: numpy.ndarray = None, image: numpy.ndarray = None, labels: numpy.ndarray = None, input_pixelsize: tuple[float, float, float] = (1, 1, 1), output_pixelsize: tuple[float, float, float] = (1, 1, 1), order: int = 1, n_jobs: int = -1) -> numpy.ndarray\n",
      "    Resizes an input image to have isotropic voxel dimensions.\n",
      "    \n",
      "    Parameters:\n",
      "    - mask: numpy array, input mask\n",
      "    - image: numpy array, input image\n",
      "    - labels: numpy array, input labels\n",
      "    - input_pixelsize: tuple of floats, input pixel dimensions (e.g. in microns)\n",
      "    - output_pixelsize: tuple of floats, output pixel dimensions (e.g. in microns)\n",
      "    - order: int, order of interpolation for resizing (defaults to 1 for\n",
      "      linear interpolation). Choose 0 for nearest-neighbor interpolation\n",
      "      (e.g. for label images)\n",
      "    - n_jobs: int, optional number of parallel jobs for resizing (default: -1)\n",
      "    \n",
      "    Returns:\n",
      "    - resized_image: numpy array, resized image with isotropic voxel dimensions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(change_arrays_pixelsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the pixelsize of the data is (1, 0.62, 0.62) µm/pix, and we want to change it to (0.621, 0.621, 0.621) µm/pix to make the image isotropic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4ec973a61947148d88f46fb988e29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making array isotropic:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "isotropic_data = change_arrays_pixelsize(image=data, input_pixelsize=(1, 0.62, 0.62),\n",
    "                                         output_pixelsize=(0.62,0.62,0.62))\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(isotropic_data, name='isotropic data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the data isotropic, it is usually easier to visually identify a typical object size in the image, that will be useful to define parameters in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_mask` computes a boolean (0/1) mask of background/foreground voxels. It is useful to remove background noise and to define the region of interest for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function compute_mask in module tapenade.preprocessing._preprocessing:\n",
      "\n",
      "compute_mask(image: numpy.ndarray, method: str, sigma_blur: float, threshold_factor: float = 1, compute_convex_hull: bool = False, registered_image: bool = False, n_jobs: int = -1) -> numpy.ndarray\n",
      "    Compute the mask for the given image using the specified method.\n",
      "    \n",
      "    Parameters:\n",
      "    - image: numpy array, input image\n",
      "    - method: str, method to use for thresholding. Can be 'snp otsu' for Signal-Noise Product thresholding,\n",
      "      or 'otsu' for Otsu's thresholding.\n",
      "    - sigma_blur: float, standard deviation of the Gaussian blur. Should typically be\n",
      "      around 1/3 of the typical object diameter.\n",
      "    - threshold_factor: float, factor to multiply the threshold (default: 1)\n",
      "    - compute_convex_hull: bool, set to True to compute the convex hull of the mask. If set to\n",
      "      False, a hole-filling operation will be performed instead.\n",
      "    - n_jobs: int, number of parallel jobs to run (-1 for using all available CPUs)\n",
      "    \n",
      "    Returns:\n",
      "    - mask: numpy array, binary mask of the same shape as the input image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(compute_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `method` can be set to the following values:\n",
    "1. `otsu` computes the mask by first blurring the image with a Gaussian filter of size `sigma_blur` (which should be set to the typical object size if it is known) and then applying Otsu's thresholding method.\n",
    "2. `snp otsu` computes a local Signal-and-Noise Product map from the image by using a Gaussian filter of size `sigma_blur` and then using Otsu's thresholding method on the map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`snp otsu` is usually the most robust method, but it is also the slowest. `otsu` is the fastest but can be sensitive to noise and large intensity variations among foreground objects. In case of doubt, it is recommended to try all methods and visually inspect the results. `compute_mask` also has a parameter `threshold_factor` that can be used to multiply the initial threshold value given by the methods above.\n",
    "\n",
    "`compute_mask` can also be called with the parameter `compute_convex_hull` to return the convex hull of the mask. This is particularly useful when artifactual holes remain in the mask, but it leads to less precise mask, and the computation takes way longer. When set to False (default), a simple hole-filling operation is performed on the mask.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560198409ed8438297bf822c924859fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Thresholding image:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1c74636d974e24bc82e61b1a6cb714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Thresholding image:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_otsu = compute_mask(isotropic_data, method='otsu', sigma_blur=object_size, threshold_factor=0.6)\n",
    "mask_snp = compute_mask(isotropic_data, method='snp otsu', sigma_blur=object_size/2)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(mask_otsu, name='mask otsu')\n",
    "    viewer.add_image(mask_snp, name='mask snp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct for intensity variations in the image, we provide the functions `global_image_equalization` and `local_image_equalization`.\n",
    "\n",
    "`global_image_equalization` equalizes the image by mapping the `perc_low` percentile to 0 and the `perc_high` percentile to 1. The image is finally clipped to the range [0, 1]. This function is useful when the image has long tails in the intensity histogram, i.e when there are very bright or very dark objects in the image, which lead to a poor contrast. Outliers can be removed by setting `perc_low` and `perc_high` to a value between 0 and 100.\n",
    "\n",
    "`local_image_equalization` computes the intensity histogram in boxes of size `box_size` (which should be set to the typical object size if it is known) centered on the vertices of a uniform 3D grid spanning the image array. For each point, the `perc_low` and `perc_high` percentiles of the histogram are computed and interpolated on each voxel of the image. The image is then equalized to map the `perc_low` percentile to 0 and the `perc_high` percentile to 1. The image is finally clipped to the range [0, 1]. This function is useful when the image has a non-uniform illumination, i.e when the intensity varies across the image, which leads to contrast variations across space.\n",
    "\n",
    "The functions have an optional parameter `mask` to specify a mask of the background/foreground voxels. If a mask is provided, values outside the mask are set to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(global_image_equalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function local_image_equalization in module tapenade.preprocessing._preprocessing:\n",
      "\n",
      "local_image_equalization(image: numpy.ndarray, box_size: int, perc_low: float, perc_high: float, mask: numpy.ndarray = None, n_jobs: int = -1) -> numpy.ndarray\n",
      "    Performs local image equalization on either a single image or a temporal stack of images.\n",
      "    Stretches the image histogram in local neighborhoods by remapping intesities in the range\n",
      "    [perc_low, perc_high] to the range [0, 1].\n",
      "    This helps to enhance the contrast and improve the visibility of structures in the image.\n",
      "    \n",
      "    Parameters:\n",
      "    - image: numpy array, input image or temporal stack of images\n",
      "    - box_size: int, size of the local neighborhood for equalization\n",
      "    - perc_low: float, lower percentile for intensity equalization\n",
      "    - perc_high: float, upper percentile for intensity equalization\n",
      "    - mask: numpy array, binary mask used to set the background to zero (optional)\n",
      "    - n_jobs: int, number of parallel jobs to use (not used currently as the function is parallelized internally)\n",
      "    \n",
      "    Returns:\n",
      "    - image_norm: numpy array, equalized image or stack of equalized images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(local_image_equalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_data_global = global_image_equalization(isotropic_data, mask=mask_snp, \n",
    "                                                  perc_low=1, perc_high=99)\n",
    "\n",
    "# in the rest of the notebook, we will use the locally equalized data\n",
    "equalized_data = local_image_equalization(isotropic_data, mask=mask_snp,\n",
    "                                            box_size=object_size,\n",
    "                                            perc_low=1, perc_high=99)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(equalized_data_global, name='equalized data global')\n",
    "    viewer.add_image(equalized_data, name='equalized data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we do not cover the image segmentation step in this notebook. We refer the reader to the `segmentation` notebook provided with this package, which uses Stardist3D to detect nuclei.\n",
    "\n",
    "For the purpose of this notebook, we will directly load a pre-segmented array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_labels = ...\n",
    "\n",
    "labels = tifffile.imread(path_to_labels)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_labels(labels, name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatio-temporal registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, we do not cover the spatio-temporal registration step in this notebook. We refer the reader to the `registration` notebook provided with this package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forcing axis alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the object of interest (e.g a gastruloid) has a preferential orientation, it can be useful to align the major axis of the objects to a specific axis. We provide the function `align_array_major_axis` to do so. It computes the principal axes of the mask and rotates the image, labels, or mask to align the major axis to the specified axis.\n",
    "\n",
    "All three arrays can be given at the same time, or only a combinations of two of them (containing the mask) can be given. The major axis is aligned with axis `target_axis` (can be 'X', 'Y', or 'Z') by rotating the image in the plane `rotation_plane` (can be 'XY', 'XZ', or 'YZ').\n",
    "If the data is temporal (i.e 4D), the major axis is computed on a mask obtained by summing the 3D masks along the time axis. If only a specific time range is to be used to compute the major axis, the parameter `temporal_slice` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function align_array_major_axis in module tapenade.preprocessing._preprocessing:\n",
      "\n",
      "align_array_major_axis(target_axis: str, rotation_plane: str, mask: numpy.ndarray, image: Optional[numpy.ndarray] = None, labels: Optional[numpy.ndarray] = None, order: int = 1, temporal_slice: Optional[int] = None, n_jobs: int = -1) -> Union[numpy.ndarray, tuple[numpy.ndarray, numpy.ndarray], tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]\n",
      "    Aligns the major axis of an array to a target axis in a specified rotation plane.\n",
      "    This function uses Principal Component Analysis (PCA) to determine the major axis of the array,\n",
      "    and then rotates the array to align the major axis with the target axis.\n",
      "    \n",
      "    Parameters:\n",
      "    - target_axis: str, the target axis to align the major axis with ('X', 'Y', or 'Z')\n",
      "    - rotation_plane: str, the rotation plane to perform the rotation in ('XY', 'XZ', or 'YZ')\n",
      "    - mask: numpy array, binary mask indicating the region of interest\n",
      "    - image: numpy array, input image or temporal stack of images (optional)\n",
      "    - labels: numpy array, labels corresponding to the mask (optional)\n",
      "    - order: int, order of interpolation for image rotation (default: 1)\n",
      "    - temporal_slice: int, optional temporal slicing applied to the mask before computing its major axis (default: None)\n",
      "    - n_jobs: int, number of parallel jobs to use (-1 for all available CPUs, 1 for sequential execution) (default: -1)\n",
      "    \n",
      "    Returns:\n",
      "    - If both image and labels are provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "        - image_rotated: numpy array, rotated image\n",
      "        - labels_rotated: numpy array, rotated labels\n",
      "    - If only image is provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "        - image_rotated: numpy array, rotated image\n",
      "    - If only labels is provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "        - labels_rotated: numpy array, rotated labels\n",
      "    - If neither image nor labels is provided:\n",
      "        - mask_rotated: numpy array, rotated mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(align_array_major_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921cd3c0f3b240a79a3565375e7103f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning mask:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3d33a6f4444495862e5def203ae1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning image:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321437a6fca54037a938b87406a10968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Aligning labels:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aligned_mask, aligned_data, align_labels = align_array_major_axis(\n",
    "    target_axis='X', rotation_plane='XY', # -> align the major axis with the X axis\n",
    "    mask=mask_snp, image=equalized_data, labels=labels,\n",
    "    temporal_slice=slice(2, 10) # -> use the frames from time 2 to 10 to compute the major axis\n",
    ")\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(aligned_mask, name='aligned mask')\n",
    "    viewer.add_image(aligned_data, name='aligned data')\n",
    "    viewer.add_labels(align_labels, name='aligned labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cropping array to mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `crop_array_using_mask` crops any array (image, labels, or mask) to the smallest bounding box containing the mask. It has an optional parameter `margin` to add a margin around the bounding box.\n",
    "\n",
    "This function can be used to drastically reduce the size of the data to process at each stage by removing useless background voxels. **Though presented at the very end of the pipeline, it can be used at any stage of the pipeline to reduce the size of the data to process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function crop_array_using_mask in module tapenade.preprocessing._preprocessing:\n",
      "\n",
      "crop_array_using_mask(mask: numpy.ndarray, image: Optional[numpy.ndarray] = None, labels: Optional[numpy.ndarray] = None, margin: int = 0, n_jobs: int = -1) -> Union[numpy.ndarray, tuple[numpy.ndarray, numpy.ndarray], tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]]\n",
      "    Crop an array using a binary mask. If the array is temporal, the cropping\n",
      "    slice is computed by aggregating mask instances at all times.\n",
      "    \n",
      "    Parameters:\n",
      "    - mask: numpy array, binary mask indicating the region of interest\n",
      "    - image: numpy array, input image or temporal stack of images (optional)\n",
      "    - labels: numpy array, labels corresponding to the mask (optional)\n",
      "    - margin: int, optional margin to add around the mask (default: 0)\n",
      "    - n_jobs: int, number of parallel jobs to use (not used currently as the function is not computationally intensive)\n",
      "    \n",
      "    Returns:\n",
      "    - cropped_array: numpy array, cropped array based on the mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(crop_array_using_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_mask, cropped_data, cropped_labels = crop_array_using_mask(\n",
    "    mask=aligned_mask, image=aligned_data, labels=align_labels, margin=0\n",
    ")\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_image(cropped_mask, name='cropped mask')\n",
    "    viewer.add_image(cropped_data, name='cropped data')\n",
    "    viewer.add_labels(cropped_labels, name='cropped labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Removing labels outside of mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the presence of noise in the image, the segmentation can sometimes produce labels that are not fully contained in the mask. We provide the function `remove_labels_outside_of_mask` to remove these labels. It takes as input the labels and the mask, and removes the labels that are not fully contained in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d6e46c63374ab58767de092bd27e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing labels outside of mask:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_filtered = remove_labels_outside_of_mask(cropped_labels, cropped_mask)\n",
    "\n",
    "if display_in_napari:\n",
    "    viewer.add_labels(labels_filtered, name='labels filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
