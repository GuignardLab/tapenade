{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed08f86b",
   "metadata": {},
   "source": [
    "# Segmentation Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d08deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from organoid import segmentation\n",
    "from organoid.preprocessing.preprocessing import (\n",
    "    make_array_isotropic,\n",
    "    compute_mask,\n",
    "    local_image_normalization,\n",
    "    align_array_major_axis,\n",
    "    crop_array_using_mask\n",
    ")\n",
    "from organoid import reconstruction\n",
    "from organoid import analysis\n",
    "from organoid import utils\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from skimage.measure import regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e5d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ...\n",
    "array = tifffile.imread(Path(path) / \"image.tif\")\n",
    "data_to_segment = array[:, 0, :, :]\n",
    "stardist_model = Path(path) / \"lennedist_3d_grid222_rays64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6cf6eba-b485-4af7-af31-2da7a5eb9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = local_image_normalization(image=data_to_segment,box_size= 25, perc_low=1,perc_high=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c13606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.465263, nms_thresh=0.3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [00:40<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "output = segmentation.predict_stardist(\n",
    "    data_normalized,\n",
    "    model_path=stardist_model,\n",
    "    input_voxelsize=[1,0.6,0.6],\n",
    "    normalize_input=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbb9edb5-a77f-4e43-a135-d2b1ecec1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite(Path(path) / \"segmentation.tif\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55d960ec-576e-43e8-b2b6-7d2e6aef0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tifffile.imread(Path(path) / \"mask.tif\")\n",
    "output[mask==0]=0\n",
    "tifffile.imwrite(Path(path) / \"segmentation_masked.tif\",output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c19caa",
   "metadata": {},
   "source": [
    "Threshold and normalize your division channel to run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ade844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_mask = ...\n",
    "path_array = ...\n",
    "path_output= ...\n",
    "num= 1\n",
    "\n",
    "mask = tifffile.imread(path_mask)\n",
    "image = tifffile.imread(path_array)\n",
    "division_channel = ...\n",
    "dapi = ...\n",
    "\n",
    "ph3=utils.normalize_by_reference_signal(signal = division_channel,reference=dapi,mask=mask)\n",
    "\n",
    "blurred_data=ndi.gaussian_filter(ph3,sigma=1.2)\n",
    "\n",
    "threshold = 0.8\n",
    "blurred_data[blurred_data<threshold]=0\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "z =int(len(blurred_data)/2)\n",
    "ax1.imshow(ph3[z,:,:])\n",
    "ax2.imshow(blurred_data[z,:,:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "stardist_model_divisions = ...\n",
    "labels_division = segmentation.predict_stardist(blurred_data, model_path=stardist_model_divisions, input_voxelsize=[1, 1, 1], normalize_input=True)\n",
    "print('Number of labels found :', len(np.unique(labels_division)))\n",
    "tifffile.imsave(path_output,labels_division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if napari installed\n",
    "# import napari\n",
    "# viewer=napari.Viewer()\n",
    "# viewer.add_image(ph3,colormap='inferno')\n",
    "# viewer.add_image(blurred_data,colormap='inferno')\n",
    "# napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec1960",
   "metadata": {},
   "source": [
    "Apply mask to remove volumes that are out of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask = ...\n",
    "mask = tifffile.imread(path_mask)\n",
    "labels_division=labels_division*mask.astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe7e0e",
   "metadata": {},
   "source": [
    "Filter wrong volumes in the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "props=regionprops(labels_division)\n",
    "histo=[]\n",
    "for prop in props :\n",
    "    bb = prop.slice #bounding box around the cell\n",
    "    cell = prop.image #boolean array giving where the cell is\n",
    "    histo.append(np.sum(cell))\n",
    "\n",
    "\n",
    "plt.hist(histo,bins=100)\n",
    "plt.title('Histogram of cell volumes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece95ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the size to filter below\n",
    "size_min =1000\n",
    "\n",
    "labels_division_filtered = labels_division.copy()\n",
    "unique_labels, label_counts = np.unique(labels_division, return_counts=True)\n",
    "\n",
    "smallest_labels = unique_labels[np.argsort(label_counts)]\n",
    "smallest_volumes = np.sort(label_counts)\n",
    "\n",
    "for label, volume in zip(smallest_labels, smallest_volumes):\n",
    "    if volume<size_min :\n",
    "        labels_division_filtered[labels_division==label]=0\n",
    "\n",
    "print('The prediction returned',len(np.unique(labels_division)),'labels, after filtering we have now',len(np.unique(labels_division_filtered)),'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewer=napari.Viewer()\n",
    "# viewer.add_image(ph3,scale=scale)\n",
    "# viewer.add_labels(labels_division_filtered,scale=scale,name='labels_filtered')\n",
    "# viewer.add_labels(labels_division,scale=scale,name='labels_not_filtered')\n",
    "# napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
